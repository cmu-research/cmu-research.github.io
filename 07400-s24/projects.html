<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <title>CMU 07-400, Spring 2024</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>

    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


    <meta http-equiv="Content-Script-Type" content="text/javascript" />
    </script>

  </head>
  <body class=container style="padding-top: 50px;">

  <style>
     .container {
    margin: 20px;
  }
  .highlight {
    background-color: #f0f0f0;
    padding: 10px;
    border-left: 5px solid #B01C33;
    margin-bottom: 20px;
  }
  .title {
    font-size: 24px;
    font-weight: bold;
  }
  .subtitle {
    font-size: 18px;
    font-weight: bold;
  }
  .abstract {
    text-indent: 20px;
  }

  #studentDropdown {
    font-size: 18px;
  }
</style>


    <nav class="navbar navbar-default navbar-fixed-top" role="navigation" style="background-color: darkred;">
      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html" style="color: white;">CMU 07-400, Spring 2024</a>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse navbar-ex1-collapse">
        <ul class="nav navbar-nav">
          <li><a href="projects.html" style="color: white;">Projects</a></li>
          <li><a href="schedule.html" style="color: white;">Schedule</a></li>
          <li><a href="assignments.html" style="color: white;">Assignments</a></li>
          <li><a href="syllabus.html" style="color: white;">Syllabus</a></li>
        </ul>
        <a href="https://piazza.com/cmu/spring2024/07400"><button type="button" class="btn btn-primary navbar-btn navbar-right" style="background-color: white; margin-right:10px; color: darkred; border: 1px solid darkred;">Piazza</button></a>
        <a href="https://www.gradescope.com/courses/708256"><button type="button" class="btn btn-primary navbar-btn navbar-right" style="background-color: white; margin-right:10px; color: darkred; border: 1px solid darkred;">Gradescope</button></a>
      </div><!-- /.navbar-collapse -->
    </nav>

    <div class="page-header">
      <h1>CMU 07-400, Spring 2024 --- Projects</h1>
    </div>


<p>A brief description of each student's project is available below. The corresponding poster will be available here later in the semester.</p>
  <br>

<h2>Select a student:</h2>
<select id="studentDropdown">
  <option value="1">Katy Yu</option>
  <option value="2">Raunak Sood</option>
  <option value="3">Kyle Booker</option>
  <option value="4">Jerick Shi</option>
  <option value="5">Emily Amspoker</option>
  <option value="6">Anisha Chatterjee</option>
  <option value="7">Tanisha Saxena</option>
  <option value="8">Maggie Cai</option>
  <option value="9">Lijie Yang</option>
  <!--<option value="10">Elizabeth Knox</option> -->
  <option value="11">Trey DuBose</option>
  <option value="12">William Gay</option>
  <option value="13">Kunal Kapoor</option>
  <option value="14">Jaehee Kim</option>
  <option value="15">Emily Estrada</option>
  <option value="16">Dongkyun Kim</option>
  <option value="17">Aaron Gostein</option>
  <option value="18">Taekseung Kim</option>
  <option value="19">Advika Jayanti</option>
</select>

<script>
  document.getElementById("studentDropdown").addEventListener("change", function() {
    var selectedValue = this.value;
    if (selectedValue === "1") {
      document.getElementById("student1").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "2") {
      document.getElementById("student2").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "3") {
      document.getElementById("student3").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "4") {
      document.getElementById("student4").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "5") {
      document.getElementById("student5").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "6") {
      document.getElementById("student6").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "7") {
      document.getElementById("student7").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "8") {
      document.getElementById("student8").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "9") {
      document.getElementById("student9").scrollIntoView({ behavior: 'smooth' });
    // } else if (selectedValue === "10") {
    //   document.getElementById("student10").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "11") {
      document.getElementById("student11").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "12") {
      document.getElementById("student12").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "13") {
      document.getElementById("student13").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "14") {
      document.getElementById("student14").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "15") {
      document.getElementById("student15").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "16") {
      document.getElementById("student16").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "17") {
      document.getElementById("student17").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "18") {
      document.getElementById("student18").scrollIntoView({ behavior: 'smooth' });
    } else if (selectedValue === "19") {
      document.getElementById("student14").scrollIntoView({ behavior: 'smooth' });
    }
  });
</script>

<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

<div id="student1" class="container">
  <div class="highlight">
    <div class="title">Gender Homophily in Open Source Software Networks <a href="posters/katy-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Katy Yu</span> (Advisor: Bogdan Vasilescu)</p>
    <b>Abstract:</b> While gender diversity in open-source software (OSS) has been widely
studied, the seemingly opposite concept, gender homophily, where individuals tend to
collaborate with those of the same gender, is less explored. It is, therefore, unclear
whether gender homophily is present in OSS. If so, what are the reasons behind it?
Does it benefit gender diversity in OSS or work against it? This study presents an initial
exploration into the existence of gender homophily within OSS networks and seeks to
unravel the underlying mechanisms of this phenomenon.

<p></p>
Our study utilizes the World of Code dataset, encompassing the FLOSS ecosystem,
which includes binary gender data inferred from contributor names. We construct OSS
collaboration networks where the ties represent the developer collaborations on projects
from 2008 to 2022 and extract the network backbone using the computed significance
score of edge weights. The network's gender composition is extremely skewed (66.38%
men, 2.70% women, 30.92% unknown), rendering direct estimation of gender
homophily unreliable. We ameliorate this problem by estimating the mean shortest path
distance of dyads of each type of gender composition and using it as a proxy for the
social proximity of ties. In addition, we use exponential random graph models to
estimate the probability of same-gender ties (i.e., the "node-match" statistic with respect
to gender).

<p></p>
Our preliminary findings from a comprehensive OSS network dataset reveal nuanced
patterns of gender-based collaboration. Moreover, women contributors exhibit a strong
preference for collaborating with the same gender, a behavior confirmed by ERGM
nodematch coefficients, where the probability of women-women ties is 28.3% more
likely than men-men ties. The observed mean shortest path length of women-women
dyads was 0.453 standard deviations shorter than the random baseline, which was in
turn longer than that of the men-men dyads (0.36 standard deviations longer than the
random baseline).

<p></p>
Our preliminary findings from a comprehensive OSS network dataset reveal nuanced patterns of gender-based collaboration. Moreover, women
contributors exhibit a strong preference for collaborating with the same gender, a behavior confirmed by ERGM nodematch coefficients, where the probability of women-women ties is 28.3% more likely than men-men ties.
The observed mean shortest path length of women-women dyads was 0.453 standard deviations shorter than the random baseline, which was in turn longer than that of the men-men dyads (0.36 standard deviations longer than the random baseline). 
</div>
</div>

<div id="student2" class="container">
  <div class="highlight">
    <div class="title">Using Large Language Models to Generate Pragmatic Test Cases <a href="posters/raunak-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Raunak Sood</span> (Advisors: Daniel Fried, Saujas Vaduguru)</p>
    <b>Abstract:</b> A major area of research in neural code generation involves synthesizing programs from sample test cases. However, the main issue with this task is that many different programs can fit the specification outlined by a given test-suit. For instance, consider the task of generating regular expressions from example strings. If we provided the example, (ab,
✔), the synthesizer could generate a+b* and a*b+c, both of which are consistent with the input example. Hence, the
goal of this area of research is to pragmatically generate programs/test-cases by reasoning about what the user
intended. In the example above, the synthesizer could reason that since the test-case was chosen intentionally, and
the character c wasn't included in the test-case, the user intended the regex a+b* instead of a*b+c. Previous work by
Vaduguru et. al tackles this problem on regular-expression synthesis by training speaker and listener models
under the Rational Speech Acts (RSA) scheme to generate test cases and programs respectively. In this research
project, we aim to adapt this technique to Python programs by generating test-cases using the large language models,
CAT-LM. Then, after the model produces these test-cases, we can use inference-time algorithms to pragmatically
select the most informative results.
</div>
</div>

<div id="student3" class="container">
  <div class="highlight">
    <div class="title">Toward Finding the Minimal Superpermutation of Six Symbols <a href="posters/kyle-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Kyle Booker</span> (Advisor: Marijn Heule)</p>
    <b>Abstract:</b> Superpermutations are combinatorial structures whose properties have remained enigmatic to
mathematicians for decades. Specifically, inquiries into the length of the minimum
superpermutation composed of \( n\) symbols have yielded mixed results. While there have been
proofs showing that the lower and upper bounds converge on long predicted values for n between
1 and 5, the value for 6 has been shown to defy such predictions and its exact value is not known.
In this paper, we present three different techniques for encoding the superpermutation problem as
an instance of the satisfiability problem. Using state-of-the-art SAT solving techniques, we
replicate the previously known bounds, opening the door to potentially solve for the case where n
is 6.
</div>
</div>

<div id="student4" class="container">
  <div class="highlight">
    <div class="title">Predicting Market Movement using Large Language Models <a href="posters/jerick-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Jerick Shi</span> (Advisor: Burton Hollifield)</p>
    <b>Abstract:</b> Predicting the movement of the stock market and other assets has been valuable over
the past few decades. Knowing how the value of a certain sector market may move in
the future provides much information for investors, as they use that information to
develop strategies in order to maximize profit or minimize risk. However, market data is
quite noisy, and it is challenging to choose the right data or the right model to create
such predictions.
<br>

Our goal is to use LLM's such as the GPT-3.5 model to create a portfolio of assets that
minimizes risk. We use data from economic texts such as the Federal Reserve Beige
Book, which provides summaries of economic conditions in different districts in the US.
Using such data, we then employ such LLM's to make predictions on the correlations
between different stocks and bonds as well as their volatility. We compare these results
with other statistical learning models and provide understanding on whether knowing
the economic conditions improves investment decisions, as well as providing an
investment strategy fullying reliant on these LLM models.
</div>
</div>

<div id="student5" class="container">
  <div class="highlight">
    <div class="title">Youth-Driven Algorithm Auditing <a href="posters/emily-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Emily Amspoker</span> (Advisors: Jaemarie Solyst, Jessica Hammer)</p>
    <b>Abstract:</b> Due to the proliferation of AI-driven technologies, youth have become key stakeholders in algorithmic systems. Youth, especially those from underserved communities, are often exposed to the harm
inflicted by biases in these algorithms. Unfortunately, they are rarely consulted by the creators of
these systems due to misconceptions about their ability to understand bias in AI at a high level
as well as notions of equity and fairness. Prior workshop-based studies, however, demonstrated
that with proper scaffolding, youth can understand and explain examples of bias in AI and ideate
their own solutions. Building off of this work, this research project seeks to further understand
how youth envision themselves changing algorithmic systems and what motivates youth to be
involved with combating algorithmic bias. This will be achieved using two primary methods: first,
a storyboarding study in which storytelling serves as a means to understand youth and parents’
conceptions of their roles in algorithm auditing. The next part of the study will focus on prototyping
and testing youth-friendly interface features within the framework of a pre-existing algorithmic
system.
</div>
</div>

<div id="student6" class="container">
  <div class="highlight">
    <div class="title">Enhancing Spatial Transcriptomics with Vision Transformers for Single-Cell Resolution Mapping <a href="posters/anisha-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Anisha Chatterjee</span> (Advisor: Jose Lugo-Martinez)</p>
    <b>Abstract:</b> Spatial transcriptomics allows scientists to measure the gene activity in a given tissue sample and map where the activity is occurring. It has greatly improved our ability to analyze gene expression within the context of different tissue structures, providing insights into cell-cell interactions and structural organization. Our project is to enhance current spatial transcriptomics methods by taking low-resolution data and transforming it to single-cell resolution. This process occurs in two steps. First, the pixel-level gene expression profile is created by applying XFuse, which relies on statistical modeling, on stained spot data. Using that data and additional cell image data, cells can then be spatially mapped and matched to their gene expression. The main challenge for this step is cell segmentation, essentially separating cells and understanding which cells belong in which spots. A popular method, SCS, first identifies cell nuclei from staining images using the Watershed algorithm. Then, the transformer model infers for each spot its relative position with respect to the nuclei of each cell. My project is to improve upon the SCS model by combining the steps from XFuse and SCS and using a vision transformer for both tasks. The goal is to improve accuracy and efficiency as more information is available.
</div>
</div>


<div id="student7" class="container">
  <div class="highlight">
    <div class="title">Hardness Estimation for Learning Parity with Noise: Adding Variety to Quantum
Cryptography <a href="posters/tanisha-motm.pdf">[Poster]</a>
</div>
    <p></p>
    <p><span class="subtitle">Tanisha Saxena</span> (Advisor: Aayush Jain)</p>
    <b>Abstract:</b> Following the discovery of quantum computing, many people have lost faith in the
power of standard cryptography measures for data protection. Rightfully so, as the
mathematical difficulty assumptions made to prove the security of many algorithms can
be undone in the quantum world. To adapt, cryptographers have come up with
“Learning with Errors” (LWE) – an assumption that holds strong even with quantum
computing power. The promising nature of LWE means many cryptographers have chosen to avoid using other assumptions out of lack of research into their strength.
Specifically, Learning Parity with Noise (LPN) has only been proven theoretically and
thus its usefulness in real applications is unknown. In this paper, we estimate the
concrete security of LPN by referencing Albrech et. al’s lattice estimator for LWE and
showing that LPN’s parameters strongly influence its security. Furthermore, we prove
the usefulness of LPN assumption by taking previous quantum algorithms and showing
how LPN simplifies the proof strategy significantly. Our research on LPN allows
cryptographers to develop a wider variety of protocols that are not only more efficient
but more tolerant against adversary attacks because they use targeted assumptions
rather than generic ones.
</div>
</div>

<div id="student8" class="container">
  <div class="highlight">
    <div class="title">AI-Based Recommendations for Learning Optimal Treatment Strategies for Sepsis with UPMC Data <a href="posters/maggie-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Maggie Cai</span> (Advisors: Adam Perer, Venkatesh Sivaraman)</p>
    <b>Abstract:</b> AI/ML in healthcare has become increasingly popular since it has the
potential to improve patient outcomes. My research builds upon previous studies on
AI-based recommendations trained on MIMIC, a large public ICU dataset, for learning
optimal treatment strategies for sepsis in intensive care. Sepsis is a condition that
occurs when a response to fight infection results in inflammation in the body, causing
the organs to fail. With sepsis treatment, patients are given a certain amount of IV fluids
and vasopressor drugs. However, treatment practices vary widely and decisional
uncertainty is common. Thus, an AI model was built to help suggest optimal treatments
for patients with sepsis. Based on patient information, such as vital signs and
fluids/vasopressors previously received, and clinician recommendations, the AI model
predicts the patient’s future disease severity. Researchers found that clinician
recommendations have little or no impact on the model’s predictions. My work involves
analyzing data from UPMC, a larger, more diverse, and not yet publicly available
dataset, to determine if the information from clinician recommendations can be more
meaningful to the AI model predictions. Analyzing the UPMC data showed that clinician
recommendations do impact the model’s predictions, contrary to the findings in MIMIC.
Using a slice-based analysis technique, I aim to determine the reason behind this
discrepancy.
</div>
</div>

<div id="student9" class="container">
  <div class="highlight">
    <div class="title">Optimization of MLSys Framework Using Speculative Inference and Asynchronous Verification <a href="posters/lijie-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Lijie Yang</span> (Advisor: Zhihao Jia)</p>
    <b>Abstract:</b> This project explores the optimization of Machine Learning Systems (MLSys) frameworks
through the implementation of speculative inference and asynchronous verification, specifically
targeting the enhancement of generative large language models (LLMs) like ChatGPT and GPT4. These models, characterized by their extensive computational and memory requirements, pose
significant challenges in achieving quick and cost-effective service. The proposed system,
SpecInfer, leverages small speculative models (SSMs) and a novel approach to token tree
verification to predict and verify LLM outputs in parallel, reducing both processing time and
computational resource demand. The innovation lies in conducting speculative inference and
token tree verification simultaneously and asynchronously, optimizing the latency issues
predominantly caused by the sequential verification process, which constitutes up to 80% of the
total latency in existing systems. The project's goals are ambitious, aiming for a 1.5x-2x speedup
in overall performance by rearchitecting the inference process to allow for more efficient
speculation and verification phases. This involves the development of a new tokenizer optimized
for speculative inference, with milestones set from initial planning to final implementation and
testing. The research also encompasses a thorough literature review on tokenization methods,
speculative inference research, and verification optimization to support the development of an
optimized framework. With the ultimate aim of contributing to the open-source community, this
project endeavors to significantly improve the inference latency of LLMs, enhancing their
accessibility and efficiency for widespread use.
</div>
</div>

<!-- <div id="student10" class="container">
  <div class="highlight">
    <div class="title">Very explicit high-dimensional expanders</div>
    <p></p>
    <p><span class="subtitle">Elizabeth Knox</span> (Advisor: Ryan O'Donnell)</p>
    <b>Abstract:</b> In this research, we investigate a class of expander graphs known as “Ramanujan
graphs”, which, while useful in applications, are mathematically complex to construct.
While they have good connectivity and pseudorandomness properties, expander graphs
are generally sparse. We aim to represent them in ways that make computing the
neighborhood of a vertex efficient, to improve the efficiency of using them in applications
like random walks. Recent work demonstrated “local” constructions of Ramanujan
graphs, which use a function to map from vertices (n-bit binary strings) to the
neighborhood of the input vertex (i.e. to a subset of n-bit binary strings) by manipulating
only a constant number of bits from the label. Such a local description would allow
constant-time lookups for the neighborhood of a vertex. The purpose of this project is to
programmatically verify the local construction of Ramanujan graphs presented in
previous work by comparing properties of the neighborhoods and adjacency matrix we
generate to known properties of Ramanujan graphs
</div>
</div> -->

<div id="student11" class="container">
  <div class="highlight">
    <div class="title">Spatially Adaptive Fluids Using Dynamic Radius in SPH Methods <a href="posters/trey-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Trey DuBose</span> (Advisor: Minchen Li)</p>
    <b>Abstract:</b> The current practice of fluid simulations with smoothed particle hydrodynamics (SPH) methods use fixed radius sizes or at least fixed sizes of integration. However, this fixes the level of detail/accuracy that is able to be represented in any simulation. In any given simulation there will be areas where high detail is necessary/beneficial and there are other areas where low detail is required and oversampling is unnecessary or redundant. With my project I aim to demonstrate how using an adaptive radius scheme can be used to improve the computational effectiveness of fluid simulations. To achieve the intended effects I will first demonstrate how to handle particles of different sizes in a complex simulation environment and secondly I will demonstrate how the radius sizes can be changed over time depending on its surrounding environment with regards to fluid density and internal forces. Lastly, I will show how my results compare to the current state of the art methods that don’t have adaptive radii.

</div>
</div>

<div id="student12" class="container">
  <div class="highlight">
    <div class="title">Deterministic Parallel Batch-Dynamic Tree Contraction <a href="posters/william-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">William Gay</span> (Advisor: Daniel Anderson)</p>
    <b>Abstract:</b> Dynamic Trees are an important tool in the design of dynamic graph algorithms. The
problem is to maintain a set of vertex disjoint trees, which can be updated by inserting
and deleting edges. The structure should be able to efficiently (\( O(log(n)) \)) answer
queries about the tree, such as the weight of a path, size of a sub-tree, or
lowest-common-ancestor of two vertices. The Rake-Compress (RC) Tree algorithm
solves this problem by iteratively contracting vertices into clusters, which are also
contracted until the structure is balanced and can be efficiently traversed. In the
parallel-batch dynamic setting, the goal is to handle multiple insert and delete
operations concurrently. Previous solutions for the parallel batch-dynamic update
problem have been randomized. We present deterministic algorithms for performing
static compression and batch-updates on RC Trees. That static algorithm performs \( O(n) \)
work and \( O(log(n)log^*(n)) \) span, and the dynamic update algorithm perform 
\( O(k~ log(1 + \frac{n}{k} )) \) work and \( O(log(n)log^*(k)) \) span on an update batch of size \( k \), 
making both algorithms work efficient with low span.
</div>
</div>

<div id="student13" class="container">
  <div class="highlight">
    <div class="title">Examining Catastrophic Forgetting in Synthetic Setups <a href="posters/kunal-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Kunal Kapoor</span> (Advisors: Suhas Kotha, Aditi Ragunathan)</p>
    <b>Abstract:</b> This research project investigates the phenomenon of forgetting in large neural networks and aims to isolate the underlying causes, moving beyond traditional capacity-related explanations. Building on the observation that model size does improve forgetting, the study employs a systematic approach to identify the "real" reasons behind forgetting and explores the hypothesis that increasing capacity changes the loss landscape, making it easier to optimize. A synthetic experiment is conducted, involving fine-tuning on Gaussian distributions, to analyze how the model output evolves during the process and assess the existence of forgetting. We find that larger networks, in our synthetic setup, tend to see an increase in forgetting. We also evaluate strategies to mitigate forgetting, such as data replay. Finally, we experimentally isolate instances of forgetting in LLMs.
</div>
</div>

<div id="student14" class="container">
  <div class="highlight">
    <div class="title">Codified audio language representations for Music Information Retrieval <a href="posters/advika-jaehee-motm.pdf">[Poster]</a>
</div>
    <p></p>
    <p><span class="subtitle">Jaehee Kim and Advika Jayanti</span> (Advisor: Chris Donahue)</p>
    <b>Abstract:</b> For this project we aim to replicate and expand upon the Music Information Retrieval (MIR) capabilities demonstrated by Jukebox, a state-of-the-art music generation model, utilizing MusicGen as a more computationally efficient alternative. Drawing inspiration from recent advancements in Natural Language Processing (NLP), we propose a novel approach that treats music as a sequence of tokens, enabling the application of NLP methods to extract musically relevant information from audio recordings. Our methodology involves pre-training MusicGen on a diverse dataset of audio recordings paired with labels, followed by fine-tuning the model for specific MIR tasks. We provide a comprehensive evaluation of MusicGen's performance on benchmark MIR tasks, including beat and chord detection, source separation, and genre classification, comparing its efficacy against Jukebox. Additionally, we explore the potential for transfer learning by leveraging MusicGen's learned representations for downstream MIR tasks, such as predicting the melodic structure and ragas in Indian classical music. By leveraging MusicGen's simplicity, we aim to provide access for better applications in music analysis and synthesis.
</div>
</div>

<div id="student15" class="container">
  <div class="highlight">
    <div class="title">Exploring Youth Empowerment in Fair AI <a href="posters/emily-estrada-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Emily Estrada</span> (Advisor: Hanan Hibshi)</p>
    <b>Abstract:</b> Due to the innovation in AI-driven technologies, youth have become key stakeholders in algorithmic systems. Youth, especially those from underserved communities, are regular users of AI and are exposed to harm from AI. Despite
this, youth are not yet included as contributors to creating responsible AI, even
though they can be sensitive to and articulate AI bias. This research project explores youth empowerment in fair AI in two ways. First, we investigate and share findings about how youth envision their role in changing AI to be more
fair through a series of educational workshops. Second, this work yields insight
into how child-ideated features can support youth in giving feedback about algorithms through low-fidelity prototyping.
</div>
</div>

<div id="student16" class="container">
  <div class="highlight">
    <div class="title">Faster Music Generation with Speculative Decoding <a href="posters/DK-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Dongkyun Kim</span> (Advisor: Chris Donahue)</p>
    <b>Abstract:</b> Autoregressive transformer-based decoders paired with quantized audio tokenizers are
the dominating method for music generation models due to their high fidelity
reconstruction capabilities. The autoregressive decoding process, however, leads to the
inference speed of these models scaling to the number of codebooks. While methods
utilizing parallel codebook interleaving patterns have been presented, their
implementation is impeded by the challenges of considering the conditional dependence
between different codebook levels.
<br>

In this work, we will introduce a novel inference strategy for music generation models by
incorporating dual pattern speculative decoding. Speculative decoding is a technique
widely used in large language models, where a smaller draft model predicts potential
future sequences and the original model validates it, thus taking advantage of
parallelism. Dual pattern speculative decoding extends this concept by utilizing the
delayed codebook pattern model as the draft model while utilizing the flatten codebook
pattern model as the validator. Thus, the method effectively leverages parallel codebook
interleaving without sacrificing the high generation capabilities of sequential methods.

Our work offers new pathways for improving the performance of music generation
systems. It also may allow real-time, high-fidelity music generation, opening up new
possibilities for interactive music applications, live performance aids, and more efficient
music composition tools.
</div>
</div>

<div id="student17" class="container">
  <div class="highlight">
    <div class="title">Proving Validity of CSL With Relaxed Memory Models <a href="posters/aaron-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Aaron Gostein</span> (Advisor: Stephen Brookes)</p>
    <b>Abstract:</b> We provide a semantics for concurrent separation logic (CSL) that is capable of reasoning about
parallel and sequential composition of concurrent programs, parameterized by a choice of
memory model characterized by a relaxation relation and a linearity guarantee. We explore
memory models such as sequential consistency (SC), which is the memory model assumed in the
original proof of validity of CSL in 2007, where each pair of memory actions appears in program
order, total store order (TSO) where each pair of writes to variables appears in program order,
and partial store order (PSO) where for each variable, each pair of writes to that variable appears
in program order. Since our semantic definitions are parametrized on the memory model used,
we obtain a framework in which it is easy to compare programs across a range of memory
models.
</div>
</div>

<div id="student18" class="container">
  <div class="highlight">
    <div class="title">Investigation on Sim search data set via ParlayANN library <a href="posters/taekseung-motm.pdf">[Poster]</a></div>
    <p></p>
    <p><span class="subtitle">Taekseung Kim</span> (Advisors: Guy Blelloch, Magdalen Dobson)</p>
    <b>Abstract:</b> There is a previous presentation about ParlayANN, which is the known fastest
nearest neighbor and range search algorithm, which is parallel and graph based.
However, on specific dataset called simsearchnet, this works slower than the known IVF
algorithm FAISS. Our group investigates the dataset in several way, and comes up with
new version of ParlayANN that works better on simsearchnet too. 
</div>
</div>

<!-- <div id="student19" class="container">
  <div class="highlight">
    <div class="title">Codified audio language representations for Music Information Retrieval</div>
    <p></p>
    <p><span class="subtitle">Advika Jayanti</span> (Advisor: Chris Donahue)</p>
    <b>Abstract:</b> For this project we aim to replicate and expand upon the Music Information Retrieval (MIR) capabilities demonstrated by Jukebox, a state-of-the-art music generation model, utilizing MusicGen as a more computationally efficient alternative. Drawing inspiration from recent advancements in Natural Language Processing (NLP), we propose a novel approach that treats music as a sequence of tokens, enabling the application of NLP methods to extract musically relevant information from audio recordings. Our methodology involves pre-training MusicGen on a diverse dataset of audio recordings paired with labels, followed by fine-tuning the model for specific MIR tasks. We provide a comprehensive evaluation of MusicGen's performance on benchmark MIR tasks, including beat and chord detection, source separation, and genre classification, comparing its efficacy against Jukebox. Additionally, we explore the potential for transfer learning by leveraging MusicGen's learned representations for downstream MIR tasks, such as predicting the melodic structure and ragas in Indian classical music. By leveraging MusicGen's simplicity, we aim to provide access for better applications in music analysis and synthesis.
</div>
</div> -->



  </body>
</html>
